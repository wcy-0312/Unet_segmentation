{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet 腫瘤 segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "class SegmentationDataset(Dataset):\n",
    "\tdef __init__(self, imagePaths, maskPaths, transforms):\n",
    "\t\t# store the image and mask filepaths, and augmentation\n",
    "\t\t# transforms\n",
    "\t\tself.imagePaths = imagePaths\n",
    "\t\tself.maskPaths = maskPaths\n",
    "\t\tself.transforms = transforms\n",
    "\tdef __len__(self):\n",
    "\t\t# return the number of total samples contained in the dataset\n",
    "\t\treturn len(self.imagePaths)\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\t# grab the image path from the current index\n",
    "\t\timagePath = self.imagePaths[idx]\n",
    "\t\t# load the image from disk, swap its channels from BGR to RGB,\n",
    "\t\t# and read the associated mask from disk in grayscale mode\n",
    "\t\timage = cv2.imread(imagePath)\n",
    "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\t\tmask = cv2.imread(self.maskPaths[idx], 0)\n",
    "\t\t# check to see if we are applying any transformations\n",
    "\t\tif self.transforms is not None:\n",
    "\t\t\t# apply the transformations to both image and its mask\n",
    "\t\t\timage = self.transforms(image)\n",
    "\t\t\tmask = self.transforms(mask)\n",
    "\t\t# return a tuple of the image and its mask\n",
    "\t\treturn (image, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Create directory\n",
    "IMAGE_DATASET_PATH = glob.glob(os.path.join('dataset', 'image', '*.jpg'))\n",
    "MASK_DATASET_PATH = glob.glob(os.path.join('dataset', 'mask', '*.jpg'))\n",
    "\n",
    "MODEL_PATH = os.path.join('output', \"unet.pth\")\n",
    "PLOT_PATH = os.path.sep.join(['output', \"plot.png\"])\n",
    "TEST_PATHS = os.path.sep.join(['output', \"test_paths.txt\"])\n",
    "\n",
    "# define the test split\n",
    "TEST_SPLIT = 0.15\n",
    "\n",
    "# determine the device to be used for training and evaluation\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# determine if we will be pinning memory during data loading\n",
    "PIN_MEMORY = True if DEVICE == \"cuda\" else False\n",
    "\n",
    "# # define the number of channels in the input, number of classes,\n",
    "# # and number of levels in the U-Net model\n",
    "# NUM_CHANNELS = 3\n",
    "# NUM_CLASSES = 1\n",
    "# NUM_LEVELS = 3\n",
    "\n",
    "# initialize learning rate, number of epochs to train for, and the\n",
    "# batch size\n",
    "INIT_LR = 0.001\n",
    "NUM_EPOCHS = 40\n",
    "BATCH_SIZE = 32 #64\n",
    "# define the input image dimensions\n",
    "INPUT_IMAGE_WIDTH = 32*7\n",
    "INPUT_IMAGE_HEIGHT = 32*4\n",
    "# define threshold to filter weak predictions\n",
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image and mask filepaths in a sorted manner\n",
    "imagePaths = sorted(IMAGE_DATASET_PATH)\n",
    "maskPaths = sorted(MASK_DATASET_PATH)\n",
    "\n",
    "# partition the data into training and testing splits using 85% of\n",
    "# the data for training and the remaining 15% for testing\n",
    "split = train_test_split(imagePaths, maskPaths,\n",
    "                         test_size=TEST_SPLIT, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack the data split\n",
    "(trainImages, testImages) = split[:2]\n",
    "(trainMasks, testMasks) = split[2:]\n",
    "\n",
    "# write the testing image paths to disk so that we can use then\n",
    "# when evaluating/testing our model\n",
    "print(\"[INFO] saving testing image paths...\")\n",
    "f = open(TEST_PATHS, \"w\")\n",
    "f.write(\"\\n\".join(testImages))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transformations\n",
    "transforms = transforms.Compose([transforms.ToPILImage(),\n",
    "                                 transforms.Resize((INPUT_IMAGE_HEIGHT, INPUT_IMAGE_WIDTH)),  \n",
    "                                 transforms.ToTensor()])\n",
    "\n",
    "# create the train and test datasets\n",
    "trainDS = SegmentationDataset(imagePaths=trainImages, maskPaths=trainMasks,\n",
    "                              transforms=transforms)\n",
    "testDS = SegmentationDataset(imagePaths=testImages, maskPaths=testMasks,\n",
    "                             transforms=transforms)\n",
    "print(f\"[INFO] found {len(trainDS)} examples in the training set...\")\n",
    "print(f\"[INFO] found {len(testDS)} examples in the test set...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training and test data loaders\n",
    "trainLoader = DataLoader(trainDS, shuffle=True,\n",
    "                         batch_size=BATCH_SIZE, pin_memory=PIN_MEMORY,\n",
    "                         )  # num_workers=os.cpu_count()\n",
    "testLoader = DataLoader(testDS, shuffle=False,\n",
    "                        batch_size=BATCH_SIZE, pin_memory=PIN_MEMORY,\n",
    "                        )  # num_workers=os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "preprocess_input = get_preprocessing_fn('resnet34', pretrained='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize loss function and optimizer\n",
    "lossFunc = BCEWithLogitsLoss()\n",
    "opt = Adam(model.parameters(), lr=INIT_LR)\n",
    "\n",
    "# calculate steps per epoch for training and test set\n",
    "trainSteps = len(trainDS) // BATCH_SIZE\n",
    "testSteps = len(testDS) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a dictionary to store training history\n",
    "H = {\"train_loss\": [], \"test_loss\": []}\n",
    "\n",
    "# loop over epochs\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "for e in tqdm(range(NUM_EPOCHS)):\n",
    "    # set the model in training mode\n",
    "    model.train()\n",
    "\n",
    "    # initialize the total training and validation loss\n",
    "    totalTrainLoss = 0\n",
    "    totalTestLoss = 0\n",
    "\n",
    "    # loop over the training set\n",
    "    for (i, (x, y)) in enumerate(trainLoader):\n",
    "        # send the input to the device\n",
    "        (x, y) = (x.to(DEVICE), y.to(DEVICE))\n",
    "\n",
    "        # perform a forward pass and the training loss\n",
    "        pred = model(x)\n",
    "        loss = lossFunc(pred, y)\n",
    "\n",
    "        # first, zero out any previously accumulated gradients, then\n",
    "        # perform backpropagation, and then update model parameters\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # add the loss to the total training loss so far\n",
    "        totalTrainLoss += loss\n",
    "        \n",
    "        # accuracy\n",
    "        # tp, fp, fn, tn = smp.metrics.get_stats(pred, y.int(), mode='binary', threshold=0.5)\n",
    "        # accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
    "        # iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "        # f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "        # print('accuracy= ', accuracy)\n",
    "        # print('iou_score= ', iou_score)\n",
    "        # print('f1_score= ', f1_score)\n",
    "        \n",
    "    # switch off autograd\n",
    "    with torch.no_grad():\n",
    "        # set the model in evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # loop over the validation set\n",
    "        for (x, y) in testLoader:\n",
    "            # send the input to the device\n",
    "            (x, y) = (x.to(DEVICE), y.to(DEVICE))\n",
    "\n",
    "            # make the predictions and calculate the validation loss\n",
    "            pred = model(x)\n",
    "            totalTestLoss += lossFunc(pred, y)\n",
    "\n",
    "    # calculate the average training and validation loss\n",
    "    avgTrainLoss = totalTrainLoss / trainSteps\n",
    "    avgTestLoss = totalTestLoss / testSteps\n",
    "    \n",
    "    # accuracy = 100*num_correct / len(trainDS)\n",
    "    \n",
    "\n",
    "    # update our training history\n",
    "    H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "    H[\"test_loss\"].append(avgTestLoss.cpu().detach().numpy())\n",
    "\n",
    "    # print the model training and validation information\n",
    "    print(\"[INFO] EPOCH: {}/{}\".format(e + 1, NUM_EPOCHS))\n",
    "    print(\"Train loss: {:.6f}, Test loss: {:.4f}, Acc: {:.6f}\".format(\n",
    "        avgTrainLoss, avgTestLoss, ))\n",
    "     \n",
    "\n",
    "\n",
    "# display the total time needed to perform the training\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "    endTime - startTime))\n",
    "\n",
    "print('min train_loss: ', min(H[\"train_loss\"]))\n",
    "print('max test_loss: ', min(H[\"test_loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # plot the training loss\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"test_loss\"], label=\"test_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(PLOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the model to disk\n",
    "torch.save(model, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plot(origImage, origMask, predMask):\n",
    "\t# initialize our figure\n",
    "\tfigure, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
    "\t\n",
    "\t# plot the original image, its mask, and the predicted mask\n",
    "\tax[0].imshow(origImage)\n",
    "\tax[1].imshow(origMask)\n",
    "\tax[2].imshow(predMask)\n",
    "\t\n",
    "\t# set the titles of the subplots\n",
    "\tax[0].set_title(\"Image\")\n",
    "\tax[1].set_title(\"Original Mask\")\n",
    "\tax[2].set_title(\"Predicted Mask\")\n",
    "\t\n",
    "\t# set the layout of the figure and display it\n",
    "\tfigure.tight_layout()\n",
    "\tfigure.show()\n",
    "\tfigure.savefig('predict.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, imagePath):\n",
    "\t# set model to evaluation mode\n",
    "\tmodel.eval()\n",
    "\t\n",
    "\t# turn off gradient tracking\n",
    "\twith torch.no_grad():\n",
    "\t\t# load the image from disk, swap its color channels, cast it\n",
    "\t\t# to float data type, and scale its pixel values\n",
    "\t\timage = cv2.imread(imagePath)\n",
    "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\t\timage = image.astype(\"float32\") / 255.0\n",
    "\t\t\n",
    "\t\t# resize the image and make a copy of it for visualization\n",
    "\t\timage = cv2.resize(image, (INPUT_IMAGE_WIDTH, INPUT_IMAGE_HEIGHT))\n",
    "\t\torig = image.copy()\n",
    "\t\t\n",
    "\t\t# find the filename and generate the path to ground truth\n",
    "\t\t# mask\n",
    "\t\t# filename = imagePath.split(os.path.sep)[-1]\n",
    "\t\t# groundTruthPath = os.path.join(MASK_DATASET_PATH,\n",
    "\t\t# \tfilename)\n",
    "\t\t\n",
    "\t\tgroundTruthPath = imagePath.replace('image', 'mask')\n",
    "\t\tprint(groundTruthPath)\n",
    "\t\t\t\n",
    "\t\t# load the ground-truth segmentation mask in grayscale mode\n",
    "\t\t# and resize it\n",
    "\t\tgtMask = cv2.imread(groundTruthPath, 0)\n",
    "\t\tgtMask = cv2.resize(gtMask, (INPUT_IMAGE_WIDTH,\n",
    "\t\t\tINPUT_IMAGE_HEIGHT))\n",
    "\t\t\t\n",
    "\t\t# make the channel axis to be the leading one, add a batch\n",
    "\t\t# dimension, create a PyTorch tensor, and flash it to the\n",
    "\t\t# current device\n",
    "\t\timage = np.transpose(image, (2, 0, 1))\n",
    "\t\timage = np.expand_dims(image, 0)\n",
    "\t\timage = torch.from_numpy(image).to(DEVICE)\n",
    "\t\t\n",
    "\t\t# make the prediction, pass the results through the sigmoid\n",
    "\t\t# function, and convert the result to a NumPy array\n",
    "\t\tpredMask = model(image).squeeze()\n",
    "\t\tpredMask = torch.sigmoid(predMask)\n",
    "\t\tpredMask = predMask.cpu().numpy()\n",
    "\t\t\n",
    "\t\t# filter out the weak predictions and convert them to integers\n",
    "\t\tpredMask = (predMask > THRESHOLD) * 255\n",
    "\t\tpredMask = predMask.astype(np.uint8)\n",
    "\t\t\n",
    "\t\t# prepare a plot for visualization\n",
    "\t\tprepare_plot(orig, gtMask, predMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image paths in our testing file and randomly select 10\n",
    "# image paths\n",
    "print(\"[INFO] loading up test image paths...\")\n",
    "imagePaths = open(TEST_PATHS).read().strip().split(\"\\n\")\n",
    "imagePath = np.random.choice(imagePaths, size=1)[0]\n",
    "\n",
    "print(imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our model from disk and flash it to the current device\n",
    "print(\"[INFO] load up model...\")\n",
    "unet = torch.load(MODEL_PATH).to(DEVICE)\n",
    "\n",
    "make_predictions(unet, imagePath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5c26057df05ae7e47c7416cbf13e16e6e6819d2130242da00c2feb7f080f170"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
